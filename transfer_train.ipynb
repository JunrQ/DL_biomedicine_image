{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:34:41 @logger.py:94]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory ./train_log/transfer/all_stages-g2-hidden-l10/ exists! Please either backup/delete it, or use a new directory.\n",
      "\u001b[32m[1030 21:34:41 @logger.py:96]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run you can choose to keep it.\n",
      "\u001b[32m[1030 21:34:41 @logger.py:97]\u001b[0m Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):\n",
      "d\n",
      "\u001b[32m[1030 21:34:43 @logger.py:74]\u001b[0m Argv: /home/fuxiaofeng/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py -f /run/user/1012/jupyter/kernel-a1e8e52c-a81c-4aa2-b00a-7afe90aaac99.json\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from config.rnn import default\n",
    "from models import RNN\n",
    "import numpy as np\n",
    "from functional import seq\n",
    "import tensorflow as tf\n",
    "from tensorpack import (TrainConfig, SyncMultiGPUTrainerParameterServer as Trainer, \n",
    "                        PredictConfig, MultiProcessDatasetPredictor as Predictor,\n",
    "                        SaverRestore, logger)\n",
    "from tensorpack.callbacks import (ScheduledHyperParamSetter, MaxSaver, ModelSaver,\n",
    "                                  DataParallelInferenceRunner as InfRunner)\n",
    "from tensorpack.predict import SimpleDatasetPredictor\n",
    "from tensorpack.tfutils.common import get_default_sess_config\n",
    "from utils import DataManager\n",
    "from utils.validation import (Accumulator, AggregateMetric, calcu_metrics)\n",
    "\n",
    "resnet_loc = \"./data/resnet_v2_101/resnet_v2_101.ckpt\"\n",
    "log_dir = './train_log/transfer/all_stages-g2-hidden-l10/'\n",
    "logger.set_logger_dir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = default\n",
    "ignore_restore = ['learning_rate', 'global_step']\n",
    "save_name = \"all-stages-max-micro-auc.tfmodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config.stages = [2, 3, 4, 5, 6]\n",
    "config.proportion = {'train': 0.55, 'val': 0.0, 'test': 0.45}\n",
    "config.annotation_number = None\n",
    "dm = DataManager.from_config(config)\n",
    "train_set = dm.get_train_set()\n",
    "test_set = dm.get_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gether data to train rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': (3209, 12627), 'train': (2898, 11880), 'val': (678, 2748)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.proportion = {'train': 0.8, 'val':0.2, 'test': 0.0}\n",
    "config.stages = [2, 3, 4, 5, 6]\n",
    "config.annotation_number = 10\n",
    "dm = DataManager.from_dataset(train_set, test_set, config)\n",
    "dm.get_num_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config.weight_decay = 0.0\n",
    "config.dropout_keep_prob = 0.5\n",
    "config.gamma = 2\n",
    "config.use_glimpse = True\n",
    "config.read_time = 5\n",
    "config.batch_size = 64\n",
    "config.use_hidden_dense = True\n",
    "\n",
    "threshold = 0.4\n",
    "train_data = dm.get_train_stream()\n",
    "val_data = dm.get_validation_stream()\n",
    "model = RNN(config, is_finetuning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:34:52 @inference_runner.py:83]\u001b[0m InferenceRunner will eval on an InputSource of size 10\n",
      "\u001b[32m[1030 21:34:53 @input_source.py:179]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[1030 21:34:53 @input_source.py:460]\u001b[0m Setting up StagingArea for GPU prefetching ...\n",
      "\u001b[32m[1030 21:34:53 @training.py:41]\u001b[0m Training a model of 2 towers\n",
      "\u001b[32m[1030 21:34:53 @training.py:92]\u001b[0m Building graph for training tower 0 on device LeastLoadedDeviceSetter-/gpu:0...\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\u001b[32m[1030 21:34:58 @training.py:92]\u001b[0m Building graph for training tower 1 on device LeastLoadedDeviceSetter-/gpu:1...\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\u001b[32m[1030 21:35:01 @model_utils.py:47]\u001b[0m \u001b[36mModel Parameters: \n",
      "\u001b[0mname                               shape                  dim  device\n",
      "---------------------------------  -----------------  -------  -------------\n",
      "custom_cnn/conv1/weights:0         [3, 3, 1024, 512]  4718592  /device:GPU:1\n",
      "custom_cnn/conv1/biases:0          [512]                  512  /device:GPU:0\n",
      "custom_cnn/batch_norm1/beta:0      [512]                  512  /device:GPU:0\n",
      "custom_cnn/batch_norm1/gamma:0     [512]                  512  /device:GPU:0\n",
      "rnn/process/read_logits/weights:0  [1024, 1]             1024  /device:GPU:0\n",
      "rnn/process/read_logits/biases:0   [1]                      1  /device:GPU:0\n",
      "rnn/process/fc_fg/weights:0        [1024, 512]         524288  /device:GPU:0\n",
      "rnn/process/fc_fg/biases:0         [512]                  512  /device:GPU:0\n",
      "rnn/process/fc_ig/weights:0        [1024, 512]         524288  /device:GPU:0\n",
      "rnn/process/fc_ig/biases:0         [512]                  512  /device:GPU:0\n",
      "hidden_fc/weights:0                [512, 512]          262144  /device:GPU:0\n",
      "hidden_fc/biases:0                 [512]                  512  /device:GPU:0\n",
      "logits/weights:0                   [512, 10]             5120  /device:GPU:0\n",
      "logits/biases:0                    [10]                    10  /device:GPU:0\u001b[36m\n",
      "Total #vars=14, #param=6038539 (23.04 MB assuming all float32)\u001b[0m\n",
      "\u001b[32m[1030 21:35:01 @base.py:207]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[1030 21:35:01 @input_source.py:179]\u001b[0m Setting up the queue 'DataParallelInferenceRunner/QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[1030 21:35:01 @predictor_factory.py:54]\u001b[0m Building predictor tower 'InferenceTower0' on device /gpu:0 ...\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\u001b[32m[1030 21:35:03 @predictor_factory.py:54]\u001b[0m Building predictor tower 'InferenceTower1' on device /gpu:1 ...\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\u001b[32m[1030 21:35:05 @summary.py:34]\u001b[0m Maintain moving average summary of 1 tensors.\n",
      "\u001b[32m[1030 21:35:05 @graph.py:91]\u001b[0m Applying collection UPDATE_OPS of 406 ops.\n",
      "\u001b[32m[1030 21:35:08 @sessinit.py:136]\u001b[0m Variable global_step:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1030 21:35:09 @sessinit.py:89]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the graph, but not found in the checkpoint: custom_cnn/conv1/weights, custom_cnn/conv1/biases, custom_cnn/batch_norm1/beta, custom_cnn/batch_norm1/gamma, custom_cnn/batch_norm1/moving_mean, custom_cnn/batch_norm1/moving_variance, rnn/process/read_logits/weights, rnn/process/read_logits/biases, rnn/process/fc_fg/weights, rnn/process/fc_fg/biases, rnn/process/fc_ig/weights, rnn/process/fc_ig/biases, hidden_fc/weights, hidden_fc/biases, logits/weights, logits/biases, learning_rate, beta1_power, beta2_power\n",
      "\u001b[32m[1030 21:35:09 @sessinit.py:89]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: global_step:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/shortcut/biases/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_1/bottleneck_v2/shortcut/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_2/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block1/unit_3/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/shortcut/biases/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_1/bottleneck_v2/shortcut/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_2/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_3/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block2/unit_4/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/shortcut/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_1/bottleneck_v2/shortcut/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_10/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_11/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_12/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_13/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_14/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_15/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_16/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_17/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_18/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_19/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_2/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_20/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_21/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_22/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_23/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_3/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_4/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_5/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_6/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_7/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_8/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block3/unit_9/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/shortcut/biases/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_1/bottleneck_v2/shortcut/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_2/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/BatchNorm/beta/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/BatchNorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/BatchNorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/BatchNorm/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv3/biases/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/conv3/weights/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/preact/beta/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/preact/gamma/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/preact/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/block4/unit_3/bottleneck_v2/preact/moving_variance/ExponentialMovingAverage:0, resnet_v2_101/conv1/biases/ExponentialMovingAverage:0, resnet_v2_101/conv1/weights/ExponentialMovingAverage:0, resnet_v2_101/logits/biases/ExponentialMovingAverage:0, resnet_v2_101/logits/biases:0, resnet_v2_101/logits/weights/ExponentialMovingAverage:0, resnet_v2_101/logits/weights:0, resnet_v2_101/postnorm/beta/ExponentialMovingAverage:0, resnet_v2_101/postnorm/gamma/ExponentialMovingAverage:0, resnet_v2_101/postnorm/moving_mean/ExponentialMovingAverage:0, resnet_v2_101/postnorm/moving_variance/ExponentialMovingAverage:0, total_loss/ExponentialMovingAverage:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:35:10 @base.py:212]\u001b[0m Creating the session ...\n",
      "\u001b[32m[1030 21:35:13 @base.py:216]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[1030 21:35:13 @sessinit.py:116]\u001b[0m Restoring checkpoint from ./data/resnet_v2_101/resnet_v2_101.ckpt ...\n",
      "INFO:tensorflow:Restoring parameters from ./data/resnet_v2_101/resnet_v2_101.ckpt\n",
      "\u001b[32m[1030 21:35:14 @base.py:223]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[1030 21:35:14 @param.py:144]\u001b[0m After epoch 0, learning_rate will change to 0.00010000\n",
      "\u001b[32m[1030 21:35:14 @concurrency.py:36]\u001b[0m Starting EnqueueThread DataParallelInferenceRunner/QueueInput/input_queue ...\n",
      "\u001b[32m[1030 21:35:16 @concurrency.py:36]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[1030 21:35:16 @input_source.py:419]\u001b[0m Pre-filling staging area ...\n",
      "\u001b[32m[1030 21:35:20 @base.py:257]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:43<00:00, 0.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:37:03 @base.py:267]\u001b[0m Epoch 1 (global_step 45) finished, time:103.25 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          |0/10[00:00<?,?it/s]/home/fuxiaofeng/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "100%|##########|10/10[00:08<00:00, 1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:37:12 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-45.\n",
      "\u001b[32m[1030 21:37:12 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m QueueInput/queue_size: 48.917\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m coverage: 3.8547\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m loss/value: 0.11362\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m macro_auc: 0.76997\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m macro_f1: 0.18805\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m mean_average_precision: 0.46024\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m micro_auc: 0.68801\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m micro_f1: 0.36458\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m one_error: 0.65625\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m ranking_loss: 0.34448\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.51596\n",
      "\u001b[32m[1030 21:37:12 @monitor.py:362]\u001b[0m training_auc: 0.71999\n",
      "\u001b[32m[1030 21:37:12 @group.py:42]\u001b[0m Callbacks took 9.106 sec in total. DataParallelInferenceRunner: 8.395sec\n",
      "\u001b[32m[1030 21:37:12 @base.py:257]\u001b[0m Start Epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:33<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:38:45 @base.py:267]\u001b[0m Epoch 2 (global_step 90) finished, time:93.06 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:38:54 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-90.\n",
      "\u001b[32m[1030 21:38:54 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.73\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.359\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m coverage: 3.8859\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m loss/value: 0.089248\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m macro_auc: 0.80893\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m macro_f1: 0.21508\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m mean_average_precision: 0.51147\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m micro_auc: 0.69762\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m micro_f1: 0.37605\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m one_error: 0.65938\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m ranking_loss: 0.3484\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.51282\n",
      "\u001b[32m[1030 21:38:54 @monitor.py:362]\u001b[0m training_auc: 0.78646\n",
      "\u001b[32m[1030 21:38:54 @group.py:42]\u001b[0m Callbacks took 8.753 sec in total. DataParallelInferenceRunner: 8.092sec\n",
      "\u001b[32m[1030 21:38:54 @base.py:257]\u001b[0m Start Epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:33<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:40:27 @base.py:267]\u001b[0m Epoch 3 (global_step 135) finished, time:93.05 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:40:35 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-135.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:40:36 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.789\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.661\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m coverage: 3.6672\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m loss/value: 0.077763\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m macro_auc: 0.84498\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m macro_f1: 0.2428\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m mean_average_precision: 0.55532\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m micro_auc: 0.7481\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m micro_f1: 0.41685\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m one_error: 0.57812\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m ranking_loss: 0.3162\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.56332\n",
      "\u001b[32m[1030 21:40:36 @monitor.py:362]\u001b[0m training_auc: 0.82413\n",
      "\u001b[32m[1030 21:40:36 @group.py:42]\u001b[0m Callbacks took 8.637 sec in total. DataParallelInferenceRunner: 8.103sec\n",
      "\u001b[32m[1030 21:40:36 @base.py:257]\u001b[0m Start Epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:33<00:00, 0.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:42:10 @base.py:267]\u001b[0m Epoch 4 (global_step 180) finished, time:93.71 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:42:18 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-180.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:42:18 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.664\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.521\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m coverage: 3.4547\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m loss/value: 0.07385\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m macro_auc: 0.8551\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m macro_f1: 0.30297\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m mean_average_precision: 0.58916\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m micro_auc: 0.77242\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m micro_f1: 0.45262\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m one_error: 0.50313\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m ranking_loss: 0.28038\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.60763\n",
      "\u001b[32m[1030 21:42:18 @monitor.py:362]\u001b[0m training_auc: 0.84764\n",
      "\u001b[32m[1030 21:42:18 @group.py:42]\u001b[0m Callbacks took 8.785 sec in total. DataParallelInferenceRunner: 8.134sec\n",
      "\u001b[32m[1030 21:42:18 @base.py:257]\u001b[0m Start Epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:43:51 @base.py:267]\u001b[0m Epoch 5 (global_step 225) finished, time:92.70 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:43:59 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-225.\n",
      "\u001b[32m[1030 21:44:00 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.606\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.368\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m coverage: 2.4609\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m loss/value: 0.069235\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m macro_auc: 0.89556\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m macro_f1: 0.4442\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m mean_average_precision: 0.6568\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m micro_auc: 0.85919\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m micro_f1: 0.55334\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m one_error: 0.48438\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m ranking_loss: 0.17574\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.67755\n",
      "\u001b[32m[1030 21:44:00 @monitor.py:362]\u001b[0m training_auc: 0.8636\n",
      "\u001b[32m[1030 21:44:00 @group.py:42]\u001b[0m Callbacks took 8.760 sec in total. DataParallelInferenceRunner: 8.107sec\n",
      "\u001b[32m[1030 21:44:00 @base.py:257]\u001b[0m Start Epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:45:33 @base.py:267]\u001b[0m Epoch 6 (global_step 270) finished, time:92.73 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:45:41 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-270.\n",
      "\u001b[32m[1030 21:45:41 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.637\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.475\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m coverage: 2.0875\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m loss/value: 0.064817\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m macro_auc: 0.90171\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m macro_f1: 0.58814\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m mean_average_precision: 0.68741\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m micro_auc: 0.89142\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m micro_f1: 0.6071\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m one_error: 0.4375\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m ranking_loss: 0.13433\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.71725\n",
      "\u001b[32m[1030 21:45:41 @monitor.py:362]\u001b[0m training_auc: 0.87639\n",
      "\u001b[32m[1030 21:45:41 @group.py:42]\u001b[0m Callbacks took 8.735 sec in total. DataParallelInferenceRunner: 8.032sec\n",
      "\u001b[32m[1030 21:45:41 @base.py:257]\u001b[0m Start Epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:47:14 @base.py:267]\u001b[0m Epoch 7 (global_step 315) finished, time:92.91 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:07<00:00, 1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:47:22 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-315.\n",
      "\u001b[32m[1030 21:47:23 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.657\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.668\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m coverage: 1.7266\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m loss/value: 0.062041\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m macro_auc: 0.91754\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m macro_f1: 0.64206\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m mean_average_precision: 0.73025\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m micro_auc: 0.91966\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m micro_f1: 0.64831\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m one_error: 0.34531\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m ranking_loss: 0.091873\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.77746\n",
      "\u001b[32m[1030 21:47:23 @monitor.py:362]\u001b[0m training_auc: 0.88604\n",
      "\u001b[32m[1030 21:47:23 @group.py:42]\u001b[0m Callbacks took 8.603 sec in total. DataParallelInferenceRunner: 7.939sec\n",
      "\u001b[32m[1030 21:47:23 @base.py:257]\u001b[0m Start Epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:33<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:48:56 @base.py:267]\u001b[0m Epoch 8 (global_step 360) finished, time:93.01 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:49:04 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-360.\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.561\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.51\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m coverage: 1.6594\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m loss/value: 0.060741\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m macro_auc: 0.91905\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m macro_f1: 0.6386\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m mean_average_precision: 0.73162\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m micro_auc: 0.91824\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m micro_f1: 0.64997\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m one_error: 0.37344\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m ranking_loss: 0.086855\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.77381\n",
      "\u001b[32m[1030 21:49:04 @monitor.py:362]\u001b[0m training_auc: 0.89394\n",
      "\u001b[32m[1030 21:49:04 @group.py:42]\u001b[0m Callbacks took 8.445 sec in total. DataParallelInferenceRunner: 8.223sec\n",
      "\u001b[32m[1030 21:49:04 @base.py:257]\u001b[0m Start Epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:50:37 @base.py:267]\u001b[0m Epoch 9 (global_step 405) finished, time:92.34 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:07<00:00, 1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:50:45 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-405.\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.545\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.533\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m coverage: 1.7141\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m loss/value: 0.057598\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m macro_auc: 0.90522\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m macro_f1: 0.61316\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m mean_average_precision: 0.69524\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m micro_auc: 0.90499\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m micro_f1: 0.62649\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m one_error: 0.32812\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m ranking_loss: 0.087465\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.79026\n",
      "\u001b[32m[1030 21:50:45 @monitor.py:362]\u001b[0m training_auc: 0.90085\n",
      "\u001b[32m[1030 21:50:45 @group.py:42]\u001b[0m Callbacks took 8.237 sec in total. DataParallelInferenceRunner: 7.978sec\n",
      "\u001b[32m[1030 21:50:45 @base.py:257]\u001b[0m Start Epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:52:18 @base.py:267]\u001b[0m Epoch 10 (global_step 450) finished, time:92.81 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:52:26 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-450.\n",
      "\u001b[32m[1030 21:52:26 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.582\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.434\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m coverage: 1.5016\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m loss/value: 0.053945\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m macro_auc: 0.92401\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m macro_f1: 0.67273\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m mean_average_precision: 0.74684\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m micro_auc: 0.93103\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m micro_f1: 0.68533\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m one_error: 0.29219\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m ranking_loss: 0.068176\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.81822\n",
      "\u001b[32m[1030 21:52:26 @monitor.py:362]\u001b[0m training_auc: 0.90693\n",
      "\u001b[32m[1030 21:52:26 @group.py:42]\u001b[0m Callbacks took 8.777 sec in total. DataParallelInferenceRunner: 8.071sec\n",
      "\u001b[32m[1030 21:52:26 @base.py:257]\u001b[0m Start Epoch 11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:33<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:53:59 @base.py:267]\u001b[0m Epoch 11 (global_step 495) finished, time:93.04 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:07<00:00, 1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:54:08 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-495.\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.523\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.458\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m coverage: 1.5375\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m loss/value: 0.053042\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m macro_auc: 0.9256\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m macro_f1: 0.65145\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m mean_average_precision: 0.75198\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m micro_auc: 0.92757\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m micro_f1: 0.67199\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m one_error: 0.31094\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m ranking_loss: 0.072727\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.8095\n",
      "\u001b[32m[1030 21:54:08 @monitor.py:362]\u001b[0m training_auc: 0.91196\n",
      "\u001b[32m[1030 21:54:08 @group.py:42]\u001b[0m Callbacks took 8.273 sec in total. DataParallelInferenceRunner: 7.983sec\n",
      "\u001b[32m[1030 21:54:08 @base.py:257]\u001b[0m Start Epoch 12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:33<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:55:41 @base.py:267]\u001b[0m Epoch 12 (global_step 540) finished, time:93.19 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:55:49 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-540.\n",
      "\u001b[32m[1030 21:55:50 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.607\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.534\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m coverage: 1.4781\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m loss/value: 0.052455\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m macro_auc: 0.92985\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m macro_f1: 0.6763\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m mean_average_precision: 0.75562\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m micro_auc: 0.94087\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m micro_f1: 0.68286\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m one_error: 0.25469\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m ranking_loss: 0.065787\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.83447\n",
      "\u001b[32m[1030 21:55:50 @monitor.py:362]\u001b[0m training_auc: 0.91642\n",
      "\u001b[32m[1030 21:55:50 @group.py:42]\u001b[0m Callbacks took 8.975 sec in total. DataParallelInferenceRunner: 8.200sec\n",
      "\u001b[32m[1030 21:55:50 @base.py:257]\u001b[0m Start Epoch 13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:57:23 @base.py:267]\u001b[0m Epoch 13 (global_step 585) finished, time:92.85 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:57:31 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-585.\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.583\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.394\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m coverage: 1.4578\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m loss/value: 0.048133\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m macro_auc: 0.92955\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m macro_f1: 0.68486\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m mean_average_precision: 0.74902\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m micro_auc: 0.94048\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m micro_f1: 0.69193\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m one_error: 0.24063\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m ranking_loss: 0.061725\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.84439\n",
      "\u001b[32m[1030 21:57:31 @monitor.py:362]\u001b[0m training_auc: 0.92074\n",
      "\u001b[32m[1030 21:57:31 @group.py:42]\u001b[0m Callbacks took 8.294 sec in total. DataParallelInferenceRunner: 8.009sec\n",
      "\u001b[32m[1030 21:57:31 @base.py:257]\u001b[0m Start Epoch 14 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:59:04 @base.py:267]\u001b[0m Epoch 14 (global_step 630) finished, time:92.67 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 21:59:12 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-630.\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.647\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.45\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m coverage: 1.4875\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m loss/value: 0.047578\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m macro_auc: 0.92823\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m macro_f1: 0.67397\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m mean_average_precision: 0.75657\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m micro_auc: 0.93811\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m micro_f1: 0.68228\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m one_error: 0.25625\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m ranking_loss: 0.066222\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.83215\n",
      "\u001b[32m[1030 21:59:12 @monitor.py:362]\u001b[0m training_auc: 0.92444\n",
      "\u001b[32m[1030 21:59:12 @group.py:42]\u001b[0m Callbacks took 8.424 sec in total. DataParallelInferenceRunner: 8.153sec\n",
      "\u001b[32m[1030 21:59:12 @base.py:257]\u001b[0m Start Epoch 15 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:00:45 @base.py:267]\u001b[0m Epoch 15 (global_step 675) finished, time:92.72 sec.\n",
      "\u001b[32m[1030 22:00:45 @param.py:144]\u001b[0m After epoch 15, learning_rate will change to 0.00001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:07<00:00, 1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:00:53 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-675.\n",
      "\u001b[32m[1030 22:00:54 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.613\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.578\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m coverage: 1.4344\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m loss/value: 0.046104\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m macro_auc: 0.92936\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m macro_f1: 0.69215\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m mean_average_precision: 0.77056\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m micro_auc: 0.94275\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m micro_f1: 0.69978\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m one_error: 0.25781\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m ranking_loss: 0.061057\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.83633\n",
      "\u001b[32m[1030 22:00:54 @monitor.py:362]\u001b[0m training_auc: 0.92778\n",
      "\u001b[32m[1030 22:00:54 @group.py:42]\u001b[0m Callbacks took 8.701 sec in total. DataParallelInferenceRunner: 7.980sec\n",
      "\u001b[32m[1030 22:00:54 @base.py:257]\u001b[0m Start Epoch 16 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:33<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:02:27 @base.py:267]\u001b[0m Epoch 16 (global_step 720) finished, time:93.13 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:02:35 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-720.\n",
      "\u001b[32m[1030 22:02:36 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.593\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.464\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m coverage: 1.4531\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m loss/value: 0.04349\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m macro_auc: 0.93184\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m macro_f1: 0.68987\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m mean_average_precision: 0.76191\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m micro_auc: 0.94339\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m micro_f1: 0.70261\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m one_error: 0.24219\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m ranking_loss: 0.06205\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.83851\n",
      "\u001b[32m[1030 22:02:36 @monitor.py:362]\u001b[0m training_auc: 0.93112\n",
      "\u001b[32m[1030 22:02:36 @group.py:42]\u001b[0m Callbacks took 8.998 sec in total. DataParallelInferenceRunner: 8.041sec\n",
      "\u001b[32m[1030 22:02:36 @base.py:257]\u001b[0m Start Epoch 17 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:33<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:04:09 @base.py:267]\u001b[0m Epoch 17 (global_step 765) finished, time:93.13 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:07<00:00, 1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:04:17 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-765.\n",
      "\u001b[32m[1030 22:04:17 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.533\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.555\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m coverage: 1.4469\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m loss/value: 0.042288\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m macro_auc: 0.93412\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m macro_f1: 0.69131\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m mean_average_precision: 0.76592\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m micro_auc: 0.94409\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m micro_f1: 0.70444\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m one_error: 0.25781\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m ranking_loss: 0.061709\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.83755\n",
      "\u001b[32m[1030 22:04:17 @monitor.py:362]\u001b[0m training_auc: 0.93406\n",
      "\u001b[32m[1030 22:04:17 @group.py:42]\u001b[0m Callbacks took 8.598 sec in total. DataParallelInferenceRunner: 7.958sec\n",
      "\u001b[32m[1030 22:04:17 @base.py:257]\u001b[0m Start Epoch 18 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:05:50 @base.py:267]\u001b[0m Epoch 18 (global_step 810) finished, time:92.89 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:05:59 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-810.\n",
      "\u001b[32m[1030 22:05:59 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.485\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.43\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m coverage: 1.4391\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m loss/value: 0.041076\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m macro_auc: 0.93294\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m macro_f1: 0.69797\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m mean_average_precision: 0.77123\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m micro_auc: 0.94419\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m micro_f1: 0.70461\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m one_error: 0.25\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m ranking_loss: 0.062222\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.84091\n",
      "\u001b[32m[1030 22:05:59 @monitor.py:362]\u001b[0m training_auc: 0.93677\n",
      "\u001b[32m[1030 22:05:59 @group.py:42]\u001b[0m Callbacks took 8.764 sec in total. DataParallelInferenceRunner: 8.029sec\n",
      "\u001b[32m[1030 22:05:59 @base.py:257]\u001b[0m Start Epoch 19 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:33<00:00, 0.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:07:32 @base.py:267]\u001b[0m Epoch 19 (global_step 855) finished, time:93.14 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:07:41 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-855.\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.581\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.401\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m coverage: 1.4516\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m loss/value: 0.041098\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m macro_auc: 0.93193\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m macro_f1: 0.69988\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m mean_average_precision: 0.7737\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m micro_auc: 0.94386\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m micro_f1: 0.70469\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m one_error: 0.25156\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m ranking_loss: 0.062453\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.83722\n",
      "\u001b[32m[1030 22:07:41 @monitor.py:362]\u001b[0m training_auc: 0.9392\n",
      "\u001b[32m[1030 22:07:41 @group.py:42]\u001b[0m Callbacks took 8.377 sec in total. DataParallelInferenceRunner: 8.093sec\n",
      "\u001b[32m[1030 22:07:41 @base.py:257]\u001b[0m Start Epoch 20 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|45/45[01:32<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:09:13 @base.py:267]\u001b[0m Epoch 20 (global_step 900) finished, time:92.22 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|10/10[00:08<00:00, 1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1030 22:09:21 @saver.py:89]\u001b[0m Model saved to ./train_log/transfer/all_stages-g2-hidden-l10/model-900.\n",
      "\u001b[32m[1030 22:09:22 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.524\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.392\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m coverage: 1.4328\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m loss/value: 0.039914\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m macro_auc: 0.93428\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m macro_f1: 0.70258\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m mean_average_precision: 0.77726\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m micro_auc: 0.94559\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m micro_f1: 0.70824\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m one_error: 0.225\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m ranking_loss: 0.059616\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.84881\n",
      "\u001b[32m[1030 22:09:22 @monitor.py:362]\u001b[0m training_auc: 0.9415\n",
      "\u001b[32m[1030 22:09:22 @group.py:42]\u001b[0m Callbacks took 8.823 sec in total. DataParallelInferenceRunner: 8.076sec\n",
      "\u001b[32m[1030 22:09:22 @base.py:271]\u001b[0m Training has finished!\n",
      "\u001b[32m[1030 22:09:22 @input_source.py:147]\u001b[0m EnqueueThread DataParallelInferenceRunner/QueueInput/input_queue Exited.\n",
      "\u001b[32m[1030 22:09:22 @input_source.py:147]\u001b[0m EnqueueThread QueueInput/input_queue Exited.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_config = TrainConfig(model=model, dataflow=train_data,\n",
    "                           callbacks=[\n",
    "                               ScheduledHyperParamSetter('learning_rate', [(0, 1e-4), (15, 1e-5)]),\n",
    "                               InfRunner(val_data, [AggregateMetric(config.validation_metrics, threshold)],\n",
    "                                         [0, 1]),\n",
    "                               ModelSaver(var_collections='model_variables'),\n",
    "                               MaxSaver('micro_auc', save_name),\n",
    "                           ],\n",
    "                           session_init=SaverRestore(\n",
    "                               model_path=resnet_loc, ignore=ignore_restore),\n",
    "                           max_epoch=20, tower=[0, 1])\n",
    "Trainer(train_config).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Smaller Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:12:35 @logger.py:94]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory train_log/transfer/test/D1-hidden exists! Please either backup/delete it, or use a new directory.\n",
      "\u001b[32m[1029 21:12:35 @logger.py:96]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run you can choose to keep it.\n",
      "\u001b[32m[1029 21:12:35 @logger.py:97]\u001b[0m Select Action: k (keep) / b (backup) / d (delete) / n (new) / q (quit):\n",
      "d\n",
      "\u001b[32m[1029 21:12:37 @logger.py:74]\u001b[0m Argv: /home/fuxiaofeng/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py -f /run/user/1012/jupyter/kernel-9d57e237-8682-4c42-be42-415ed30e28a8.json\n"
     ]
    }
   ],
   "source": [
    "test_loc_dir = 'train_log/transfer/test/D1-hidden'\n",
    "model_name = 'train_log/transfer/all_stages-g2-hidden/all-stages-max-micro-auc.tfmodel'\n",
    "test_save_name = 'max-training-auc.tfmodel'\n",
    "ignore_restore = ['learning_rate', 'global_step', 'logits/weights', 'logits/biases', \n",
    "                  'custom_cnn/conv1/weights', 'custom_cnn/conv1/biases',\n",
    "                  'custom_cnn/batch_norm1/beta', 'custom_cnn/batch_norm1/gamma',\n",
    "                  'custom_cnn/batch_norm1/moving_mean', 'custom_cnn/batch_norm1/moving_variance',\n",
    "                  'hidden_fc/weights', 'hidden_fc/biases']\n",
    "logger.set_logger_dir(test_loc_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config.weight_decay = 0.0\n",
    "config.dropout_keep_prob = 0.5\n",
    "config.gamma = 2\n",
    "config.use_glimpse = True\n",
    "config.read_time = 5\n",
    "config.batch_size = 64\n",
    "config.use_hidden_dense = True\n",
    "\n",
    "threshold = 0.4\n",
    "config.proportion = {'train': 1.0, 'val': 0.0, 'test': 0.0}\n",
    "config.stages = [2]\n",
    "config.annotation_number = 10\n",
    "dm = DataManager.from_dataset(train_set, test_set, config)\n",
    "train_data = dm.get_train_stream()\n",
    "val_data = dm.get_test_stream()\n",
    "model = RNN(config, is_finetuning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:12:39 @inference_runner.py:83]\u001b[0m InferenceRunner will eval on an InputSource of size 11\n",
      "\u001b[32m[1029 21:12:40 @input_source.py:179]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[1029 21:12:40 @input_source.py:460]\u001b[0m Setting up StagingArea for GPU prefetching ...\n",
      "\u001b[32m[1029 21:12:40 @training.py:41]\u001b[0m Training a model of 2 towers\n",
      "\u001b[32m[1029 21:12:40 @training.py:92]\u001b[0m Building graph for training tower 0 on device LeastLoadedDeviceSetter-/gpu:0...\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\u001b[32m[1029 21:12:45 @training.py:92]\u001b[0m Building graph for training tower 1 on device LeastLoadedDeviceSetter-/gpu:1...\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\u001b[32m[1029 21:12:48 @model_utils.py:47]\u001b[0m \u001b[36mModel Parameters: \n",
      "\u001b[0mname                            shape                  dim  device\n",
      "------------------------------  -----------------  -------  -------------\n",
      "custom_cnn/conv1/weights:0      [3, 3, 1024, 512]  4718592  /device:GPU:1\n",
      "custom_cnn/conv1/biases:0       [512]                  512  /device:GPU:0\n",
      "custom_cnn/batch_norm1/beta:0   [512]                  512  /device:GPU:0\n",
      "custom_cnn/batch_norm1/gamma:0  [512]                  512  /device:GPU:0\n",
      "hidden_fc/weights:0             [512, 512]          262144  /device:GPU:0\n",
      "hidden_fc/biases:0              [512]                  512  /device:GPU:0\n",
      "logits/weights:0                [512, 10]             5120  /device:GPU:0\n",
      "logits/biases:0                 [10]                    10  /device:GPU:0\u001b[36m\n",
      "Total #vars=8, #param=4987914 (19.03 MB assuming all float32)\u001b[0m\n",
      "\u001b[32m[1029 21:12:48 @base.py:207]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[1029 21:12:48 @input_source.py:179]\u001b[0m Setting up the queue 'DataParallelInferenceRunner/QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[1029 21:12:48 @predictor_factory.py:54]\u001b[0m Building predictor tower 'InferenceTower0' on device /gpu:0 ...\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\u001b[32m[1029 21:12:49 @predictor_factory.py:54]\u001b[0m Building predictor tower 'InferenceTower1' on device /gpu:1 ...\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\u001b[32m[1029 21:12:52 @summary.py:34]\u001b[0m Maintain moving average summary of 1 tensors.\n",
      "\u001b[32m[1029 21:12:52 @graph.py:91]\u001b[0m Applying collection UPDATE_OPS of 406 ops.\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable custom_cnn/conv1/weights:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable custom_cnn/conv1/biases:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable custom_cnn/batch_norm1/beta:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable custom_cnn/batch_norm1/gamma:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable custom_cnn/batch_norm1/moving_mean:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable custom_cnn/batch_norm1/moving_variance:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable hidden_fc/weights:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable hidden_fc/biases:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable logits/weights:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:136]\u001b[0m Variable logits/biases:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:89]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the graph, but not found in the checkpoint: learning_rate, beta1_power, beta2_power, global_step\n",
      "\u001b[32m[1029 21:12:55 @sessinit.py:89]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: custom_cnn/batch_norm1/beta:0, custom_cnn/batch_norm1/gamma:0, custom_cnn/batch_norm1/moving_mean:0, custom_cnn/batch_norm1/moving_variance:0, custom_cnn/conv1/biases:0, custom_cnn/conv1/weights:0, hidden_fc/biases:0, hidden_fc/weights:0, logits/biases:0, logits/weights:0\n",
      "\u001b[32m[1029 21:12:56 @base.py:212]\u001b[0m Creating the session ...\n",
      "\u001b[32m[1029 21:12:59 @base.py:216]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[1029 21:12:59 @sessinit.py:116]\u001b[0m Restoring checkpoint from train_log/transfer/all_stages-g2-hidden/all-stages-max-micro-auc.tfmodel ...\n",
      "INFO:tensorflow:Restoring parameters from train_log/transfer/all_stages-g2-hidden/all-stages-max-micro-auc.tfmodel\n",
      "\u001b[32m[1029 21:13:00 @base.py:223]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[1029 21:13:00 @param.py:144]\u001b[0m After epoch 0, learning_rate will change to 0.00010000\n",
      "\u001b[32m[1029 21:13:00 @concurrency.py:36]\u001b[0m Starting EnqueueThread DataParallelInferenceRunner/QueueInput/input_queue ...\n",
      "\u001b[32m[1029 21:13:02 @concurrency.py:36]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[1029 21:13:02 @input_source.py:419]\u001b[0m Pre-filling staging area ...\n",
      "\u001b[32m[1029 21:13:05 @base.py:257]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:35<00:00, 0.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:13:40 @base.py:267]\u001b[0m Epoch 1 (global_step 13) finished, time:35.14 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          |0/11[00:00<?,?it/s]/home/fuxiaofeng/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "100%|##########|11/11[00:10<00:00, 0.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:13:51 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-13.\n",
      "\u001b[32m[1029 21:13:51 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 50\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m QueueInput/queue_size: 39.865\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m coverage: 3.4134\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m loss/value: 0.18256\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m macro_auc: 0.66507\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m macro_f1: 0.2569\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m mean_average_precision: 0.40976\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m micro_auc: 0.74073\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m micro_f1: 0.47209\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m one_error: 0.48295\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m ranking_loss: 0.23216\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.64654\n",
      "\u001b[32m[1029 21:13:51 @monitor.py:362]\u001b[0m training_auc: 0.64592\n",
      "\u001b[32m[1029 21:13:51 @group.py:42]\u001b[0m Callbacks took 11.000 sec in total. DataParallelInferenceRunner: 10.254sec\n",
      "\u001b[32m[1029 21:13:51 @base.py:257]\u001b[0m Start Epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:14:18 @base.py:267]\u001b[0m Epoch 2 (global_step 26) finished, time:26.72 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:14:27 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-26.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:14:28 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.739\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m QueueInput/queue_size: 46.271\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m coverage: 3.6122\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m loss/value: 0.14037\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m macro_auc: 0.71062\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m macro_f1: 0.26447\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m mean_average_precision: 0.44106\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m micro_auc: 0.76632\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m micro_f1: 0.47192\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m one_error: 0.49148\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m ranking_loss: 0.24798\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.61666\n",
      "\u001b[32m[1029 21:14:28 @monitor.py:362]\u001b[0m training_auc: 0.7048\n",
      "\u001b[32m[1029 21:14:28 @group.py:42]\u001b[0m Callbacks took 10.041 sec in total. DataParallelInferenceRunner: 9.409sec\n",
      "\u001b[32m[1029 21:14:28 @base.py:257]\u001b[0m Start Epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:27<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:14:55 @base.py:267]\u001b[0m Epoch 3 (global_step 39) finished, time:27.03 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:15:05 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-39.\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.661\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m QueueInput/queue_size: 48.284\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m coverage: 3.8182\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m loss/value: 0.12211\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m macro_auc: 0.70906\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m macro_f1: 0.25445\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m mean_average_precision: 0.4302\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m micro_auc: 0.74311\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m micro_f1: 0.44511\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m one_error: 0.5696\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m ranking_loss: 0.26881\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.57722\n",
      "\u001b[32m[1029 21:15:05 @monitor.py:362]\u001b[0m training_auc: 0.73879\n",
      "\u001b[32m[1029 21:15:05 @group.py:42]\u001b[0m Callbacks took 9.694 sec in total. DataParallelInferenceRunner: 9.500sec\n",
      "\u001b[32m[1029 21:15:05 @base.py:257]\u001b[0m Start Epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:15:31 @base.py:267]\u001b[0m Epoch 4 (global_step 52) finished, time:26.69 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:15:41 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-52.\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.745\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.018\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m coverage: 3.75\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m loss/value: 0.11158\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m macro_auc: 0.72845\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m macro_f1: 0.27762\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m mean_average_precision: 0.43079\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m micro_auc: 0.75387\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m micro_f1: 0.46557\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m one_error: 0.65909\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m ranking_loss: 0.27169\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.55954\n",
      "\u001b[32m[1029 21:15:41 @monitor.py:362]\u001b[0m training_auc: 0.76442\n",
      "\u001b[32m[1029 21:15:41 @group.py:42]\u001b[0m Callbacks took 9.622 sec in total. DataParallelInferenceRunner: 9.386sec\n",
      "\u001b[32m[1029 21:15:41 @base.py:257]\u001b[0m Start Epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:16:08 @base.py:267]\u001b[0m Epoch 5 (global_step 65) finished, time:26.92 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:16:18 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-65.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:16:18 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.631\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.356\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m coverage: 3.6477\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m loss/value: 0.10382\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m macro_auc: 0.76013\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m macro_f1: 0.33439\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m mean_average_precision: 0.46215\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m micro_auc: 0.76884\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m micro_f1: 0.49401\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m one_error: 0.67045\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m ranking_loss: 0.25739\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.5726\n",
      "\u001b[32m[1029 21:16:18 @monitor.py:362]\u001b[0m training_auc: 0.78381\n",
      "\u001b[32m[1029 21:16:18 @group.py:42]\u001b[0m Callbacks took 10.155 sec in total. DataParallelInferenceRunner: 9.533sec\n",
      "\u001b[32m[1029 21:16:18 @base.py:257]\u001b[0m Start Epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:16:45 @base.py:267]\u001b[0m Epoch 6 (global_step 78) finished, time:26.74 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:16:55 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-78.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:16:55 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.671\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.527\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m coverage: 3.5341\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m loss/value: 0.099081\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m macro_auc: 0.77277\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m macro_f1: 0.3492\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m mean_average_precision: 0.47902\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m micro_auc: 0.77575\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m micro_f1: 0.48473\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m one_error: 0.64489\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m ranking_loss: 0.24366\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.58867\n",
      "\u001b[32m[1029 21:16:55 @monitor.py:362]\u001b[0m training_auc: 0.79803\n",
      "\u001b[32m[1029 21:16:55 @group.py:42]\u001b[0m Callbacks took 10.323 sec in total. DataParallelInferenceRunner: 9.641sec\n",
      "\u001b[32m[1029 21:16:55 @base.py:257]\u001b[0m Start Epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:27<00:00, 0.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:17:23 @base.py:267]\u001b[0m Epoch 7 (global_step 91) finished, time:27.44 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:17:32 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-91.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:17:33 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.693\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.645\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m coverage: 3.3722\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m loss/value: 0.094802\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m macro_auc: 0.77141\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m macro_f1: 0.38352\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m mean_average_precision: 0.47332\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m micro_auc: 0.79966\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m micro_f1: 0.51906\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m one_error: 0.4858\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m ranking_loss: 0.21651\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.65168\n",
      "\u001b[32m[1029 21:17:33 @monitor.py:362]\u001b[0m training_auc: 0.81002\n",
      "\u001b[32m[1029 21:17:33 @group.py:42]\u001b[0m Callbacks took 10.236 sec in total. DataParallelInferenceRunner: 9.611sec\n",
      "\u001b[32m[1029 21:17:33 @base.py:257]\u001b[0m Start Epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:17:59 @base.py:267]\u001b[0m Epoch 8 (global_step 104) finished, time:26.66 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:18:09 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-104.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:18:10 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.712\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.763\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m coverage: 3.2685\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m loss/value: 0.090774\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m macro_auc: 0.78325\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m macro_f1: 0.38311\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m mean_average_precision: 0.50032\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m micro_auc: 0.8115\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m micro_f1: 0.52763\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m one_error: 0.44034\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m ranking_loss: 0.20046\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.67553\n",
      "\u001b[32m[1029 21:18:10 @monitor.py:362]\u001b[0m training_auc: 0.82062\n",
      "\u001b[32m[1029 21:18:10 @group.py:42]\u001b[0m Callbacks took 10.234 sec in total. DataParallelInferenceRunner: 9.615sec\n",
      "\u001b[32m[1029 21:18:10 @base.py:257]\u001b[0m Start Epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:18:37 @base.py:267]\u001b[0m Epoch 9 (global_step 117) finished, time:26.89 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:18:46 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-117.\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.668\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.66\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m coverage: 3.4886\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m loss/value: 0.088961\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m macro_auc: 0.78382\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m macro_f1: 0.37255\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m mean_average_precision: 0.50063\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m micro_auc: 0.78525\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m micro_f1: 0.50586\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m one_error: 0.45881\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m ranking_loss: 0.21792\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.64265\n",
      "\u001b[32m[1029 21:18:46 @monitor.py:362]\u001b[0m training_auc: 0.82881\n",
      "\u001b[32m[1029 21:18:46 @group.py:42]\u001b[0m Callbacks took 9.735 sec in total. DataParallelInferenceRunner: 9.530sec\n",
      "\u001b[32m[1029 21:18:46 @base.py:257]\u001b[0m Start Epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:19:13 @base.py:267]\u001b[0m Epoch 10 (global_step 130) finished, time:26.66 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:19:23 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-130.\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.729\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.545\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m coverage: 3.5724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m loss/value: 0.085944\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m macro_auc: 0.7845\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m macro_f1: 0.41131\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m mean_average_precision: 0.49829\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m micro_auc: 0.77235\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m micro_f1: 0.51106\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m one_error: 0.59659\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m ranking_loss: 0.23734\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.58691\n",
      "\u001b[32m[1029 21:19:23 @monitor.py:362]\u001b[0m training_auc: 0.836\n",
      "\u001b[32m[1029 21:19:23 @group.py:42]\u001b[0m Callbacks took 9.852 sec in total. DataParallelInferenceRunner: 9.641sec\n",
      "\u001b[32m[1029 21:19:23 @base.py:257]\u001b[0m Start Epoch 11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:27<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:19:50 @base.py:267]\u001b[0m Epoch 11 (global_step 143) finished, time:27.20 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:20:00 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-143.\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.725\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.471\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m coverage: 3.5625\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m loss/value: 0.083663\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m macro_auc: 0.78612\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m macro_f1: 0.42488\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m mean_average_precision: 0.50139\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m micro_auc: 0.7666\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m micro_f1: 0.50922\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m one_error: 0.60795\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m ranking_loss: 0.23597\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.58705\n",
      "\u001b[32m[1029 21:20:00 @monitor.py:362]\u001b[0m training_auc: 0.84287\n",
      "\u001b[32m[1029 21:20:00 @group.py:42]\u001b[0m Callbacks took 9.643 sec in total. DataParallelInferenceRunner: 9.413sec\n",
      "\u001b[32m[1029 21:20:00 @base.py:257]\u001b[0m Start Epoch 12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:20:26 @base.py:267]\u001b[0m Epoch 12 (global_step 156) finished, time:26.68 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:20:36 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-156.\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.768\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.573\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m coverage: 3.2486\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m loss/value: 0.08305\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m macro_auc: 0.79713\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m macro_f1: 0.44419\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m mean_average_precision: 0.5128\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m micro_auc: 0.80624\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m micro_f1: 0.53999\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m one_error: 0.51847\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m ranking_loss: 0.20334\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.64653\n",
      "\u001b[32m[1029 21:20:36 @monitor.py:362]\u001b[0m training_auc: 0.8479\n",
      "\u001b[32m[1029 21:20:36 @group.py:42]\u001b[0m Callbacks took 10.034 sec in total. DataParallelInferenceRunner: 9.784sec\n",
      "\u001b[32m[1029 21:20:36 @base.py:257]\u001b[0m Start Epoch 13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:21:03 @base.py:267]\u001b[0m Epoch 13 (global_step 169) finished, time:26.87 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:21:13 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-169.\n",
      "\u001b[32m[1029 21:21:13 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.721\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.483\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m coverage: 3.1477\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m loss/value: 0.080285\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m macro_auc: 0.8029\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m macro_f1: 0.46558\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m mean_average_precision: 0.52173\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m micro_auc: 0.82796\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m micro_f1: 0.56124\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m one_error: 0.4517\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m ranking_loss: 0.18642\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.68486\n",
      "\u001b[32m[1029 21:21:13 @monitor.py:362]\u001b[0m training_auc: 0.85342\n",
      "\u001b[32m[1029 21:21:13 @group.py:42]\u001b[0m Callbacks took 10.236 sec in total. DataParallelInferenceRunner: 9.501sec\n",
      "\u001b[32m[1029 21:21:13 @base.py:257]\u001b[0m Start Epoch 14 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:21:40 @base.py:267]\u001b[0m Epoch 14 (global_step 182) finished, time:26.81 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:21:50 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-182.\n",
      "\u001b[32m[1029 21:21:50 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.719\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.671\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m coverage: 3.1108\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m loss/value: 0.078095\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m macro_auc: 0.81965\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m macro_f1: 0.47771\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m mean_average_precision: 0.55142\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m micro_auc: 0.83105\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m micro_f1: 0.57043\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m one_error: 0.49574\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m ranking_loss: 0.19036\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.6679\n",
      "\u001b[32m[1029 21:21:50 @monitor.py:362]\u001b[0m training_auc: 0.85841\n",
      "\u001b[32m[1029 21:21:50 @group.py:42]\u001b[0m Callbacks took 10.019 sec in total. DataParallelInferenceRunner: 9.330sec\n",
      "\u001b[32m[1029 21:21:50 @base.py:257]\u001b[0m Start Epoch 15 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:22:17 @base.py:267]\u001b[0m Epoch 15 (global_step 195) finished, time:26.93 sec.\n",
      "\u001b[32m[1029 21:22:17 @param.py:144]\u001b[0m After epoch 15, learning_rate will change to 0.00001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:22:27 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-195.\n",
      "\u001b[32m[1029 21:22:28 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.636\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.675\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m coverage: 3.1605\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m learning_rate: 0.0001\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m loss/value: 0.075782\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m macro_auc: 0.82924\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m macro_f1: 0.50703\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m mean_average_precision: 0.58491\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m micro_auc: 0.83263\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m micro_f1: 0.5781\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m one_error: 0.53693\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m ranking_loss: 0.19302\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.64878\n",
      "\u001b[32m[1029 21:22:28 @monitor.py:362]\u001b[0m training_auc: 0.86306\n",
      "\u001b[32m[1029 21:22:28 @group.py:42]\u001b[0m Callbacks took 10.327 sec in total. DataParallelInferenceRunner: 9.598sec\n",
      "\u001b[32m[1029 21:22:28 @base.py:257]\u001b[0m Start Epoch 16 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:22:54 @base.py:267]\u001b[0m Epoch 16 (global_step 208) finished, time:26.48 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:23:04 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-208.\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.701\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.676\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m coverage: 3.0753\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m loss/value: 0.073449\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m macro_auc: 0.82505\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m macro_f1: 0.51303\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m mean_average_precision: 0.5607\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m micro_auc: 0.83251\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m micro_f1: 0.57846\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m one_error: 0.52983\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m ranking_loss: 0.18439\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.65548\n",
      "\u001b[32m[1029 21:23:04 @monitor.py:362]\u001b[0m training_auc: 0.86764\n",
      "\u001b[32m[1029 21:23:04 @group.py:42]\u001b[0m Callbacks took 9.942 sec in total. DataParallelInferenceRunner: 9.671sec\n",
      "\u001b[32m[1029 21:23:04 @base.py:257]\u001b[0m Start Epoch 17 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:27<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:23:31 @base.py:267]\u001b[0m Epoch 17 (global_step 221) finished, time:27.06 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:23:41 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-221.\n",
      "\u001b[32m[1029 21:23:41 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.667\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.681\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m coverage: 3.0099\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m loss/value: 0.073529\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m macro_auc: 0.82576\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m macro_f1: 0.50942\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m mean_average_precision: 0.56762\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m micro_auc: 0.83894\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m micro_f1: 0.58608\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m one_error: 0.50852\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m ranking_loss: 0.17675\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.66988\n",
      "\u001b[32m[1029 21:23:41 @monitor.py:362]\u001b[0m training_auc: 0.87132\n",
      "\u001b[32m[1029 21:23:41 @group.py:42]\u001b[0m Callbacks took 10.349 sec in total. DataParallelInferenceRunner: 9.661sec\n",
      "\u001b[32m[1029 21:23:41 @base.py:257]\u001b[0m Start Epoch 18 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:24:08 @base.py:267]\u001b[0m Epoch 18 (global_step 234) finished, time:26.66 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:24:18 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-234.\n",
      "\u001b[32m[1029 21:24:19 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.731\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.808\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m coverage: 2.9361\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m loss/value: 0.071545\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m macro_auc: 0.82932\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m macro_f1: 0.51281\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m mean_average_precision: 0.56134\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m micro_auc: 0.84522\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m micro_f1: 0.59244\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m one_error: 0.48011\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m ranking_loss: 0.16979\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.68071\n",
      "\u001b[32m[1029 21:24:19 @monitor.py:362]\u001b[0m training_auc: 0.87522\n",
      "\u001b[32m[1029 21:24:19 @group.py:42]\u001b[0m Callbacks took 10.457 sec in total. DataParallelInferenceRunner: 9.726sec\n",
      "\u001b[32m[1029 21:24:19 @base.py:257]\u001b[0m Start Epoch 19 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:27<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:24:46 @base.py:267]\u001b[0m Epoch 19 (global_step 247) finished, time:27.06 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:24:55 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-247.\n",
      "\u001b[32m[1029 21:24:56 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.775\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.747\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m coverage: 2.9091\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m loss/value: 0.070633\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m macro_auc: 0.82807\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m macro_f1: 0.52224\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m mean_average_precision: 0.56916\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m micro_auc: 0.84869\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m micro_f1: 0.5974\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m one_error: 0.45028\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m ranking_loss: 0.16432\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.69206\n",
      "\u001b[32m[1029 21:24:56 @monitor.py:362]\u001b[0m training_auc: 0.87865\n",
      "\u001b[32m[1029 21:24:56 @group.py:42]\u001b[0m Callbacks took 10.242 sec in total. DataParallelInferenceRunner: 9.540sec\n",
      "\u001b[32m[1029 21:24:56 @base.py:257]\u001b[0m Start Epoch 20 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|13/13[00:26<00:00, 0.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:25:23 @base.py:267]\u001b[0m Epoch 20 (global_step 260) finished, time:26.69 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|11/11[00:09<00:00, 0.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:25:33 @saver.py:89]\u001b[0m Model saved to train_log/transfer/test/D1-hidden/model-260.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 21:25:33 @saver.py:158]\u001b[0m Model with maximum 'micro_auc' saved.\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m DataParallelInferenceRunner/QueueInput/queue_size: 49.679\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m QueueInput/queue_size: 49.581\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m coverage: 2.8693\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m learning_rate: 1e-05\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m loss/value: 0.071146\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m macro_auc: 0.8272\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m macro_f1: 0.50828\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m mean_average_precision: 0.5668\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m micro_auc: 0.85402\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m micro_f1: 0.59322\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m one_error: 0.42614\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m ranking_loss: 0.16158\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m ranking_mean_average_precision: 0.70786\n",
      "\u001b[32m[1029 21:25:33 @monitor.py:362]\u001b[0m training_auc: 0.88147\n",
      "\u001b[32m[1029 21:25:33 @group.py:42]\u001b[0m Callbacks took 10.342 sec in total. DataParallelInferenceRunner: 9.759sec\n",
      "\u001b[32m[1029 21:25:33 @base.py:271]\u001b[0m Training has finished!\n",
      "\u001b[32m[1029 21:25:33 @input_source.py:147]\u001b[0m EnqueueThread QueueInput/input_queue Exited.\n",
      "\u001b[32m[1029 21:25:33 @input_source.py:147]\u001b[0m EnqueueThread DataParallelInferenceRunner/QueueInput/input_queue Exited.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_config = TrainConfig(model=model, dataflow=train_data,\n",
    "                           callbacks=[\n",
    "                               ScheduledHyperParamSetter('learning_rate', [(0, 1e-4), (15, 1e-5)]),\n",
    "                               InfRunner(val_data, [AggregateMetric(config.validation_metrics, threshold)],\n",
    "                                         [0, 1]),\n",
    "                               ModelSaver(var_collections='model_variables'),\n",
    "                               MaxSaver('micro_auc', test_save_name),\n",
    "                           ],\n",
    "                           session_init=SaverRestore(\n",
    "                               model_path=model_name, ignore=ignore_restore),\n",
    "                           max_epoch=20, tower=[0, 1])\n",
    "Trainer(train_config).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'resnet_v2_101/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/conv1/biases:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/preact/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/shortcut/weights:0' shape=(1, 1, 64, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/shortcut/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/weights:0' shape=(1, 1, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv3/weights:0' shape=(1, 1, 64, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_1/bottleneck_v2/conv3/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/preact/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/preact/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/preact/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/preact/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/weights:0' shape=(1, 1, 256, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv3/weights:0' shape=(1, 1, 64, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_2/bottleneck_v2/conv3/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/preact/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/preact/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/preact/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/preact/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/weights:0' shape=(1, 1, 256, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv3/weights:0' shape=(1, 1, 64, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block1/unit_3/bottleneck_v2/conv3/biases:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/preact/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/preact/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/preact/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/preact/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/shortcut/weights:0' shape=(1, 1, 256, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/shortcut/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/weights:0' shape=(1, 1, 256, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv3/weights:0' shape=(1, 1, 128, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_1/bottleneck_v2/conv3/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/preact/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/preact/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/preact/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/preact/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/weights:0' shape=(1, 1, 512, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv3/weights:0' shape=(1, 1, 128, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_2/bottleneck_v2/conv3/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/preact/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/preact/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/preact/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/preact/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/weights:0' shape=(1, 1, 512, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv3/weights:0' shape=(1, 1, 128, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_3/bottleneck_v2/conv3/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/preact/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/preact/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/preact/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/preact/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/weights:0' shape=(1, 1, 512, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv3/weights:0' shape=(1, 1, 128, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block2/unit_4/bottleneck_v2/conv3/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/preact/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/preact/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/preact/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/preact/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/shortcut/weights:0' shape=(1, 1, 512, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/shortcut/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/weights:0' shape=(1, 1, 512, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_1/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_2/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_3/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_4/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_5/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_6/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_7/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_8/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_9/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_10/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_11/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_12/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_13/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_14/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_15/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_16/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_17/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_18/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_19/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_20/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_21/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_22/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv3/weights:0' shape=(1, 1, 256, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block3/unit_23/bottleneck_v2/conv3/biases:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/preact/beta:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/preact/gamma:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/preact/moving_mean:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/preact/moving_variance:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/shortcut/weights:0' shape=(1, 1, 1024, 2048) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/shortcut/biases:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/weights:0' shape=(1, 1, 1024, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv3/weights:0' shape=(1, 1, 512, 2048) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_1/bottleneck_v2/conv3/biases:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/preact/beta:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/preact/gamma:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/preact/moving_mean:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/preact/moving_variance:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/weights:0' shape=(1, 1, 2048, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv3/weights:0' shape=(1, 1, 512, 2048) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_2/bottleneck_v2/conv3/biases:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/preact/beta:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/preact/gamma:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/preact/moving_mean:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/preact/moving_variance:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/weights:0' shape=(1, 1, 2048, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/BatchNorm/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/BatchNorm/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/BatchNorm/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv1/BatchNorm/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/BatchNorm/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/BatchNorm/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/BatchNorm/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv2/BatchNorm/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv3/weights:0' shape=(1, 1, 512, 2048) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/block4/unit_3/bottleneck_v2/conv3/biases:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/postnorm/beta:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/postnorm/gamma:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/postnorm/moving_mean:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'resnet_v2_101/postnorm/moving_variance:0' shape=(2048,) dtype=float32_ref>,\n",
       " <tf.Variable 'custom_cnn/conv1/weights:0' shape=(3, 3, 1024, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'custom_cnn/conv1/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'custom_cnn/batch_norm1/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'custom_cnn/batch_norm1/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'custom_cnn/batch_norm1/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'custom_cnn/batch_norm1/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/process/fc_read/weights:0' shape=(1024, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/process/fc_read/biases:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/process/fc_fg/weights:0' shape=(1024, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/process/fc_fg/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/process/fc_ig/weights:0' shape=(1024, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/process/fc_ig/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_fc/weights:0' shape=(512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_fc/biases:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'logits/weights:0' shape=(512, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'logits/biases:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.MODEL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
