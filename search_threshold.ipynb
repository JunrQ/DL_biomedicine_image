{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\u001b[32m[1030 21:35:23 @logger.py:74]\u001b[0m Argv: /home/fuxiaofeng/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py -f /run/user/1012/jupyter/kernel-15effe74-de9e-4182-8f09-718c6089b7bb.json\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from config.rnn import default\n",
    "from models import RNN\n",
    "import numpy as np\n",
    "from functional import seq\n",
    "from multiprocessing import Process, Pipe\n",
    "import tensorflow as tf\n",
    "from tensorpack import (TrainConfig, SyncMultiGPUTrainerParameterServer as Trainer, \n",
    "                        PredictConfig, SimpleDatasetPredictor as Predictor,\n",
    "                        SaverRestore, logger)\n",
    "from tensorpack.callbacks import (ScheduledHyperParamSetter, MaxSaver, ModelSaver,\n",
    "                                  DataParallelInferenceRunner as InfRunner)\n",
    "from tensorpack.predict import SimpleDatasetPredictor\n",
    "from tensorpack.tfutils.common import get_default_sess_config\n",
    "from utils import DataManager\n",
    "from utils.validation import (Accumulator, AggregateMetric, calcu_metrics)\n",
    "\n",
    "log_dir = './train_log/threshold'\n",
    "model_loc = './train_log/transfer/all_stages-g2-hidden/all-stages-max-micro-auc.tfmodel'\n",
    "logger.set_logger_dir(log_dir, action='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = default\n",
    "config.stages = [2, 3, 4, 5, 6]\n",
    "config.proportion = {'train': 0.55, 'val': 0.0, 'test': 0.45}\n",
    "config.annotation_number = None\n",
    "dm = DataManager.from_config(config)\n",
    "train_set = dm.get_train_set()\n",
    "test_set = dm.get_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': (3209, 12627), 'train': (2898, 11880), 'val': (678, 2748)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.proportion = {'train': 0.8, 'val': 0.2, 'test': 0.0}\n",
    "config.annotation_number = 10\n",
    "config.use_hidden_dense = True\n",
    "config.batch_size = 64\n",
    "dm = DataManager.from_dataset(train_set, test_set, config)\n",
    "test_data = dm.get_test_stream()\n",
    "val_data = dm.get_validation_stream()\n",
    "dm.get_num_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_a_threshold(config, threshold, test_set, pipe):\n",
    "    model = RNN(config, is_finetuning=False)\n",
    "    tf.reset_default_graph()\n",
    "    pred_config = PredictConfig(model=model,\n",
    "                                session_init=SaverRestore(\n",
    "                                    model_path=model_loc),\n",
    "                                output_names=['logits_export', 'label'],\n",
    "                                )\n",
    "    # pred = Predictor(pred_config, test_data, nr_proc=2, ordered=False)\n",
    "    pred = Predictor(pred_config, test_set)\n",
    "\n",
    "    accumulator = seq(pred.get_result()) \\\n",
    "        .smap(lambda a, b: (a.shape[0], calcu_metrics(a, b, config.validation_metrics, threshold))) \\\n",
    "        .aggregate(Accumulator(*config.validation_metrics), lambda accu, args: accu.feed(args[0], *args[1]))\n",
    "    metrics = accumulator.retrive()\n",
    "    pipe.send(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "\u001b[32m[1030 20:57:25 @sessinit.py:89]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the graph, but not found in the checkpoint: rnn/process/read_logits/weights, rnn/process/read_logits/biases\n",
      "\u001b[32m[1030 20:57:25 @sessinit.py:89]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: rnn/process/fc_read/biases:0, rnn/process/fc_read/weights:0\n",
      "\u001b[32m[1030 20:57:30 @sessinit.py:116]\u001b[0m Restoring checkpoint from ./train_log/transfer/all_stages-g2-hidden/all-stages-max-micro-auc.tfmodel ...\n",
      "INFO:tensorflow:Restoring parameters from ./train_log/transfer/all_stages-g2-hidden/all-stages-max-micro-auc.tfmodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|8         |1/12[00:04<00:44, 0.25it/s]/home/fuxiaofeng/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "100%|##########|12/12[00:23<00:00, 0.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_average_precision': 0.67727302818714141, 'macro_auc': 0.94019598495560486, 'micro_auc': 0.94986288468996161, 'macro_f1': 0.55964114972090628, 'micro_f1': 0.6164147167799231, 'ranking_mean_average_precision': 0.74284324807887125, 'coverage': 3.9700520833333335, 'ranking_loss': 0.054404820978869568, 'one_error': 0.30598958333333331}\n"
     ]
    }
   ],
   "source": [
    "threshold_choices = [0.4]\n",
    "metrics = []\n",
    "for thrsd in threshold_choices:\n",
    "    receiver, sender = Pipe(duplex=False)\n",
    "    child = Process(target=run_a_threshold, args=(config, thrsd, val_data, sender))\n",
    "    child.start()\n",
    "    child.join()\n",
    "    metric = receiver.recv()\n",
    "    print(metric)\n",
    "    metrics.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
