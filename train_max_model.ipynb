{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\u001b[32m[1029 10:54:56 @logger.py:74]\u001b[0m Argv: /home/fuxiaofeng/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py -f /run/user/1012/jupyter/kernel-34fcf0de-44ab-480a-ae3c-57bbfccdb2d9.json\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from config.max_model import ModelConfig\n",
    "from functional import seq\n",
    "from models import MaxModel\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorpack import (TrainConfig, SyncMultiGPUTrainerParameterServer as Trainer, \n",
    "                        PredictConfig, MultiProcessDatasetPredictor as Predictor,\n",
    "                        SaverRestore, logger)\n",
    "from tensorpack.callbacks import (ScheduledHyperParamSetter, MaxSaver, ModelSaver,\n",
    "                                  InferenceRunner as InfRunner)\n",
    "from tensorpack.predict import SimpleDatasetPredictor\n",
    "from tensorpack.tfutils.common import get_default_sess_config\n",
    "from utils import DataManager\n",
    "from utils.validation import (Accumulator, AggregateMetric, calcu_metrics)\n",
    "\n",
    "vgg_loc = \"./data/vgg_16.ckpt\"\n",
    "# log 存放位置\n",
    "#     log 中包含 Inferencer 给出的 metrics， 可用tensorboard查看\n",
    "#     命令 tensorboard --logdir XXXX --port XXXX\n",
    "#     类似 jupyter notebook，tensorboard 需要通过浏览器使用， 请建立 SSH tunnel\n",
    "#     log_dir 下也会存放 ModelSaver 生成的 checkpoint文件，这些文件占用空间很大，\n",
    "#     建议将 log_dir 放在 /data 分区下，或建立软链接\n",
    "log_dir = 'train_log/vgg_max_model/'\n",
    "logger.set_logger_dir(log_dir, action='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 可以在这里修改配置\n",
    "config = ModelConfig()\n",
    "# 新增：（width, height) 图片大小。DataManager需要知道图片的大小。这里也可以进行resize操作\n",
    "config.image_size = (320, 128)\n",
    "# 新增：划分比例\n",
    "config.proportion = {'train': 0.6, 'val': 0.2, 'test': 0.2}\n",
    "# 新增: 在划分数据集时，允许比例的误差\n",
    "config.tolerance_margin = 0.02\n",
    "# 新增：在划分数据集时，是否打乱顺序\n",
    "#    设置为 True，每次划分的结果会不同\n",
    "#    不过现在我把随机数种子固定了，无论true 或 false每次划分的结果都一样\n",
    "#    之后可能会取消固定随机数种子\n",
    "config.shuffle_separation = True\n",
    "# 新增：要使用哪些方向\n",
    "config.directions = ['ventral', 'dorsal', 'lateral']\n",
    "# 新增：DataManager 需要知道 batch_size\n",
    "config.batch_size = 20\n",
    "# 为了兼容 DataManager， 我把 stage_allowed 改为 stages \n",
    "config.stages = [6]\n",
    "# 同样的， top_k_labels 改为 annotation_number\n",
    "config.annotation_number = 10\n",
    "# max_img 改为 max_sequence_length\n",
    "config.max_sequence_length = 10\n",
    "# 请修改为图片所在位置\n",
    "config.image_directory = str(Path.home()) + \\\n",
    "    \"/Documents/flyexpress/DL_biomedicine_image/data/pic_data/\"\n",
    "\n",
    "# standard_images.csv 与 standard_annotations.csv 附带在 repo 的 data 目录下\n",
    "config.image_table_location = str(Path.home()) + \\\n",
    "    \"/Documents/flyexpress/DL_biomedicine_image/data/standard_images.csv\"\n",
    "config.annotation_table_location = str(Path.home()) + \\\n",
    "    \"/Documents/flyexpress/DL_biomedicine_image/data/standard_annotations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从vgg checkpoint 回复权值时，要忽略的tensor名称\n",
    "ignore_restore = ['learning_rate', 'global_step']\n",
    "# 在训练中，会保存一个某个metric最大（或最小）的模型，用于之后测试\n",
    "save_name = \"max-micro_auc.ckpt\"\n",
    "# 将 probability 转化为 0， 1 的阈值\n",
    "threshold = 0.5\n",
    "# 在验证集与测试集上要计算哪些 metrics\n",
    "validation_metrics = ['mean_average_precision', 'macro_auc', 'micro_auc',\n",
    "                      'macro_f1', 'micro_f1', 'ranking_mean_average_precision',\n",
    "                      'coverage', 'ranking_loss', 'one_error']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group numbers:\n",
      "train: 1476, validation: 449, test: 527\n",
      "Image numbers:\n",
      "train: 8489, validation: 2594, test: 3087\n",
      "\n",
      "                                         train       val      test\n",
      "embryonic midgut                      1.044321  0.995556  1.125000\n",
      "ventral nerve cord                    1.748603  1.823899  1.977401\n",
      "embryonic brain                       1.860465  1.841772  2.028736\n",
      "embryonic hindgut                     2.400922  2.277372  2.513333\n",
      "embryonic dorsal epidermis            2.904762  2.741667  2.875000\n",
      "embryonic/larval muscle system        3.146067  2.870690  2.932836\n",
      "embryonic central nervous system      3.193182  3.235849  3.543103\n",
      "embryonic ventral epidermis           3.405970  3.235849  3.319672\n",
      "embryonic head epidermis              4.698842  4.907895  4.547368\n",
      "dorsal prothoracic pharyngeal muscle  5.201681  4.831169  4.988636\n"
     ]
    }
   ],
   "source": [
    "data_manager = DataManager.from_config(config)\n",
    "print(data_manager.get_imbalance_ratio())\n",
    "train_data = data_manager.get_validation_stream()\n",
    "val_data = data_manager.get_test_stream()\n",
    "test_data = data_manager.get_test_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 10:55:23 @inference_runner.py:83]\u001b[0m InferenceRunner will eval on an InputSource of size 26\n",
      "\u001b[32m[1029 10:55:23 @input_source.py:179]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "\u001b[32m[1029 10:55:23 @input_source.py:460]\u001b[0m Setting up StagingArea for GPU prefetching ...\n",
      "\u001b[32m[1029 10:55:23 @training.py:41]\u001b[0m Training a model of 2 towers\n",
      "\u001b[32m[1029 10:55:23 @training.py:92]\u001b[0m Building graph for training tower 0 on device LeastLoadedDeviceSetter-/gpu:0...\n",
      "\u001b[32m[1029 10:55:24 @regularize.py:109]\u001b[0m Add REGULARIZATION_LOSSES of 7 tensors on the total cost.\n",
      "\u001b[32m[1029 10:55:24 @training.py:92]\u001b[0m Building graph for training tower 1 on device LeastLoadedDeviceSetter-/gpu:1...\n",
      "\u001b[32m[1029 10:55:24 @regularize.py:109]\u001b[0m Add REGULARIZATION_LOSSES of 7 tensors on the total cost.\n",
      "\u001b[32m[1029 10:55:25 @model_utils.py:47]\u001b[0m \u001b[36mModel Parameters: \n",
      "\u001b[0mname                               shape                 dim  device\n",
      "---------------------------------  ----------------  -------  -------------\n",
      "adaption/conv1/kernel:0            [3, 3, 512, 512]  2359296  /device:GPU:0\n",
      "adaption/conv1/bias:0              [512]                 512  /device:GPU:1\n",
      "adaption/conv2/kernel:0            [3, 3, 512, 512]  2359296  /device:GPU:1\n",
      "adaption/conv2/bias:0              [512]                 512  /device:GPU:0\n",
      "adaption/conv3/kernel:0            [3, 3, 512, 512]  2359296  /device:GPU:0\n",
      "adaption/conv3/bias:0              [512]                 512  /device:GPU:1\n",
      "adaption/net_reduce_fc/kernel:0    [1, 1, 512, 64]     32768  /device:GPU:1\n",
      "adaption/net_reduce_fc/bias:0      [64]                   64  /device:GPU:1\n",
      "adaption/dense/kernel:0            [5376, 128]        688128  /device:GPU:1\n",
      "adaption/dense/bias:0              [128]                 128  /device:GPU:1\n",
      "adaption/net_max_feature/kernel:0  [1, 1, 512, 512]   262144  /device:GPU:1\n",
      "adaption/net_max_feature/bias:0    [512]                 512  /device:GPU:1\n",
      "adaption/adaption_output/kernel:0  [640, 10]            6400  /device:GPU:1\n",
      "adaption/adaption_output/bias:0    [10]                   10  /device:GPU:1\u001b[36m\n",
      "Total #vars=14, #param=8069578 (30.78 MB assuming all float32)\u001b[0m\n",
      "\u001b[32m[1029 10:55:25 @base.py:207]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[1029 10:55:25 @predictor_factory.py:54]\u001b[0m Building predictor tower 'InferenceTower' on device /gpu:0 ...\n",
      "\u001b[32m[1029 10:55:25 @summary.py:34]\u001b[0m Maintain moving average summary of 1 tensors.\n",
      "\u001b[32m[1029 10:55:25 @graph.py:91]\u001b[0m Applying collection UPDATE_OPS of 2 ops.\n",
      "\u001b[32m[1029 10:55:25 @sessinit.py:136]\u001b[0m Variable global_step:0 in the graph will be not loaded from the checkpoint!\n",
      "\u001b[32m[1029 10:55:25 @sessinit.py:89]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the graph, but not found in the checkpoint: adaption/conv1/kernel, adaption/conv1/bias, adaption/conv2/kernel, adaption/conv2/bias, adaption/conv3/kernel, adaption/conv3/bias, adaption/net_reduce_fc/kernel, adaption/net_reduce_fc/bias, adaption/dense/kernel, adaption/dense/bias, adaption/net_max_feature/kernel, adaption/net_max_feature/bias, adaption/adaption_output/kernel, adaption/adaption_output/bias, learning_rate, beta1_power, beta2_power\n",
      "\u001b[32m[1029 10:55:25 @sessinit.py:89]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: global_step:0, vgg_16/conv5/conv5_1/biases:0, vgg_16/conv5/conv5_1/weights:0, vgg_16/conv5/conv5_2/biases:0, vgg_16/conv5/conv5_2/weights:0, vgg_16/conv5/conv5_3/biases:0, vgg_16/conv5/conv5_3/weights:0, vgg_16/fc6/biases:0, vgg_16/fc6/weights:0, vgg_16/fc7/biases:0, vgg_16/fc7/weights:0, vgg_16/fc8/biases:0, vgg_16/fc8/weights:0, vgg_16/mean_rgb:0\n",
      "\u001b[32m[1029 10:55:26 @base.py:212]\u001b[0m Creating the session ...\n",
      "\u001b[32m[1029 10:55:26 @base.py:216]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[1029 10:55:26 @sessinit.py:116]\u001b[0m Restoring checkpoint from ./data/vgg_16.ckpt ...\n",
      "INFO:tensorflow:Restoring parameters from ./data/vgg_16.ckpt\n",
      "\u001b[32m[1029 10:55:26 @base.py:223]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[1029 10:55:26 @param.py:144]\u001b[0m After epoch 0, learning_rate will change to 0.00010000\n",
      "\u001b[32m[1029 10:55:27 @concurrency.py:36]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[1029 10:55:27 @input_source.py:419]\u001b[0m Pre-filling staging area ...\n",
      "\u001b[32m[1029 10:55:29 @base.py:257]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|22/22[00:17<00:00, 1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1029 10:55:46 @base.py:267]\u001b[0m Epoch 1 (global_step 22) finished, time:17.73 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_before_inference finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          |0/26[00:00<?,?it/s]/home/fuxiaofeng/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/fuxiaofeng/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "  4%|3         |1/26[00:00<00:18, 1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_on_fetches finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|7         |2/26[00:01<00:16, 1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_on_fetches finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|#1        |3/26[00:02<00:15, 1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_on_fetches finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|#5        |4/26[00:02<00:14, 1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_on_fetches finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|#9        |5/26[00:03<00:13, 1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_on_fetches finished\n"
     ]
    }
   ],
   "source": [
    "model = MaxModel(config)\n",
    "tf.reset_default_graph()\n",
    "train_config = TrainConfig(model=model, dataflow=train_data,\n",
    "                           callbacks=[\n",
    "                               # 在这里设置 learning rate\n",
    "                               ScheduledHyperParamSetter('learning_rate', [(0, 1e-4), (20, 1e-4)]),\n",
    "                               InfRunner(val_data, [AggregateMetric(validation_metrics, threshold)],\n",
    "                                         ),\n",
    "                               ModelSaver(max_to_keep=10),\n",
    "                               # 可以将micro_auc 改为其他的\n",
    "                               MaxSaver('micro_auc', save_name),\n",
    "                           ],\n",
    "                           session_init=SaverRestore(\n",
    "                               model_path=vgg_loc, ignore=ignore_restore),\n",
    "                           # 跑多少个 epoch\n",
    "                           max_epoch=2, nr_tower=2)\n",
    "Trainer(train_config).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorpack import TestDataSpeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          |26/5000[00:00<02:29,33.33it/s]\n"
     ]
    }
   ],
   "source": [
    "TestDataSpeed(val_data).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.set_printoptions(formatter={'float_kind': lambda x: '%.3f' % x})\n",
    "model = MaxModel(config)\n",
    "tf.reset_default_graph()\n",
    "pred_config = PredictConfig(model=model,\n",
    "                            session_init=SaverRestore(\n",
    "                                model_path=log_dir + save_name),\n",
    "                            output_names=['logits_export', 'label'],\n",
    "                            )\n",
    "pred = SimpleDatasetPredictor(pred_config, test_data)\n",
    "\n",
    "accumulator = seq(pred.get_result()) \\\n",
    "    .smap(lambda a, b: (a.shape[0], calcu_metrics(a, b, config.validation_metrics, threshold))) \\\n",
    "    .aggregate(Accumulator(*config.validation_metrics), lambda accu, args: accu.feed(args[0], *args[1]))\n",
    "metrics = accumulator.retrive()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
